<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Akash Kumar</title>
  
  <meta name="author" content="Akash Kumar">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<!-- <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>"> -->
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Akash Kumar</name>
              </p>
              <!-- <p style="font-size:15px"> -->
              <p> 
                I am a fifth year PhD student at Center for Research in Computer Vision (CRCV), University of Central Florida (UCF), under the supervision of <a href="https://www.crcv.ucf.edu/person/rawat/" style="font-size:15px">Prof. Yogesh Singh Rawat</a>. 
              </p>
              <p style="font-size:15px">
                I have a broad interest in deep learning and computer vision. My current research mainly focuses on limited label understanding for multimodal and unimodal dense video tasks.
              </p>
              <p style="color:red;"><b> Looking for research intern/full-time positions (Summer'25)! Feel free to drop me an email. </b></p>
              <p style="text-align:center">
                <a href="mailto:akash.kumar@ucf.edu">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=gsHhV5kAAAAJ&view_op=list_works&sortby=pubdate">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/AKASH2907">Github</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/akash-kumar-498600113/">LinkedIn</a> &nbsp/&nbsp
                <a href="data/AkashKumar_CV.pdf">CV</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/profile_pic.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/profile_pic.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Intern Experience</heading>
            </td>
          </tr>
          </table>
          <table width="100%" align="center" border="0" cellpadding="20"></tbody>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/amazon_logo.png' width="110">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <strong>Applied Scientist Intern</strong>
                <br> Visual Research, Palo Alto, USA. Summer 2024
                <br> Host: <a href="https://shanyang.me/">Shan Yang</a>,
                <a href="https://www.amazon.science/author/junbang-liang">Junbang Liang</a>
                <!-- <a href="https://www.amazon.science/author/yusheng-xie">Yusheng Xie</a>,
                <a href="https://scholar.google.com/citations?user=Z_WrhK8AAAAJ&hl=en">Mu Li</a> -->
                <p></p>
                <p> Towards Open-vocabulary video object understanding.</p>
              </td>
            </tr>
          </tr>
          </table>

          <!-- <table width="100%" align="center" border="0" cellpadding="20"></tbody>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/bytedance.jpg' width="120">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <strong>Research Intern</strong>
                <br> ByteDance Inc., Mountain View, USA. Summer 2021
                <br> Host: <a href="https://sites.google.com/site/linjieyang89/">Linjie Yang</a>,
                <a href="https://scholar.google.com.sg/citations?user=OEZ816YAAAAJ&hl=en">Xiaojie Jin</a>
                <p></p>
                <p>Efficient neural architecture search.</p>
              </td>
            </tr>
          </tr>
          </table> -->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="mira_stop()" onmouseover="mira_start()"></tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/cospal.png' width="160">
              </div>
              <script type="text/javascript">
                function mira_start() {
                  document.getElementById('mira_image').style.opacity = "1";
                }

                function mira_stop() {
                  document.getElementById('mira_image').style.opacity = "0";
                }
                mira_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <!-- <a href="https://arxiv.org/abs/2412.07072"> -->
                <papertitle>Contextual Self-paced Learning for Weakly Supervised Spatio-Temporal Video Grounding</papertitle>
              </a>
              <br>
              <strong> Akash Kumar, </strong>
              Zsolt Kira, 
              Yogesh Singh Rawat
              <br>
              <em>Under review 
              <br>
              <!-- <a href="https://arxiv.org/abs/2412.07072">paper</a> &nbsp/&nbsp -->
              <!-- <a href="https://github.com/AKASH2907/stable-mean-teacher">code</a> -->
              <p></p>
              <p>
                First foundation model adaptation for dense multimodal video detection task without any labels. Context aware and self-paced progressive scene learning approach.
              </p>
            </td>
          </tr>

          <tr onmouseout="mira_stop()" onmouseover="mira_start()"></tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/smt.png' width="160">
              </div>
              <script type="text/javascript">
                function mira_start() {
                  document.getElementById('mira_image').style.opacity = "1";
                }

                function mira_stop() {
                  document.getElementById('mira_image').style.opacity = "0";
                }
                mira_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2412.07072">
                <papertitle>Stable Mean Teacher for Semi-Supervised Video Action Detection</papertitle>
              </a>
              <br>
              <strong> Akash Kumar, </strong>
              Sirshapan Mitra, 
              Yogesh Singh Rawat
              <br>
              <em>Association for the Advancement of Artificial Intelligence (<strong>AAAI</strong>)</em>, 2025
              <br>
              <a href="https://arxiv.org/abs/2412.07072">paper</a> &nbsp/&nbsp
              <a href="https://github.com/AKASH2907/stable-mean-teacher">code</a>
              <p></p>
              <p>
                Learning from mistakes on labelled set and transfer that learning to pseudo labels from unlabeled set to enhance spatio-temporal localization. 
                Class-agnostic spatio-temporal refinement module and temporal coherency constraint for better spatio-temporal localization.
              </p>
            </td>
          </tr>
          
          <tr onmouseout="mira_stop()" onmouseover="mira_start()"></tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/semi_active.png' width="160">
              </div>
              <script type="text/javascript">
                function mira_start() {
                  document.getElementById('mira_image').style.opacity = "1";
                }

                function mira_stop() {
                  document.getElementById('mira_image').style.opacity = "0";
                }
                mira_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2312.07169">
                <papertitle>Semi-supervised Active Learning for Video Action Detection</papertitle>
              </a>
              <br>
              Ayush Singh,
              Aayush J Rana,
              <strong> Akash Kumar, </strong>
              Shruti Vyas,
              Yogesh Singh Rawat
              <br>
              <em>Association for the Advancement of Artificial Intelligence (<strong>AAAI</strong>)</em>, 2024
              <br>
              <a href="https://arxiv.org/pdf/2312.07169">paper</a> &nbsp/&nbsp
              <a href="https://github.com/AKASH2907/semi-sup-active-learning">code</a>
              <p></p>
              <p>
                High-pass filtering for enhanced pseudo labels to improvise spatio-temporal localization. Simple sample augmentation strategy for informative sample selection.
              </p>
            </td>
          </tr>

          <tr onmouseout="mira_stop()" onmouseover="mira_start()"></tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/e2essl.png' width="160">
              </div>
              <script type="text/javascript">
                function mira_start() {
                  document.getElementById('mira_image').style.opacity = "1";
                }

                function mira_stop() {
                  document.getElementById('mira_image').style.opacity = "0";
                }
                mira_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Kumar_End-to-End_Semi-Supervised_Learning_for_Video_Action_Detection_CVPR_2022_paper.pdf">
                <papertitle>End-to-End Semi-Supervised Learning for Video Action Detection</papertitle>
              </a>
              <br>
              <strong> Akash Kumar, </strong>
              Yogesh Singh Rawat
              <br>
              <em>Computer Vision and Pattern Recognition Conference (<strong>CVPR</strong>)</em>, 2022
              <br>
              <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Kumar_End-to-End_Semi-Supervised_Learning_for_Video_Action_Detection_CVPR_2022_paper.pdf">paper</a> &nbsp/&nbsp
              <a href="https://github.com/AKASH2907/pi-consistency-activity-detection">code</a>
              <p></p>
              <p>
                First end-to-end semi-supervised approach for video action detection task. Short-term and long-term smoothness constraints to exploit spatio-temporal coherency.
              </p>
            </td>
          </tr>

				
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Service</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
					
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
            <td width="75%" valign="center">
              <a href="https://cvpr2022.thecvf.com/area-chairs">Reviewer, IEEE Transaction on Image Processing</a>
              <br>
              <a href="https://cvpr2022.thecvf.com/area-chairs">Reviewer, CVPR 2023, 2024, 2025</a>
              <br>
              <a href="https://cvpr2022.thecvf.com/area-chairs">Reviewer, ICLR 2023, 2024, 2025</a>
              <br>
              <a href="https://cvpr2022.thecvf.com/area-chairs">Reviewer, ECCV 2022, 2024</a>
              <br>
              <a href="https://cvpr2022.thecvf.com/area-chairs">Reviewer, ICCV 2023</a>
              <br>
              <a href="https://cvpr2022.thecvf.com/area-chairs">Reviewer, NeurIPS 2023, 2024</a>
            </td>
          </tr>

		
					
					
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>. <strong>Do not</strong> scrape the HTML from this page itself, as it includes analytics tags that you do not want on your own website &mdash; use the github code instead. Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
